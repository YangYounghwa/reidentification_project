{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPqHaoSwTiyP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOJVpeXwVoCh",
        "outputId": "307ad401-2e81-47f2-bf23-9e37ecc9e8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘ReID_attenv2’: File exists\n",
            "mkdir: cannot create directory ‘/content/dataset/’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ReID_attenv2\n",
        "!mkdir /content/dataset/\n",
        "!mkdir /content/dataset/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjd88YvBUgwp"
      },
      "outputs": [],
      "source": [
        "!unzip -qq train2022_1.zip -d /content/dataset/train/\n",
        "!unzip -qq train2022_2.zip -d /content/dataset/train/\n",
        "!unzip -qq train2022_3.zip -d /content/dataset/train/\n",
        "!unzip -qq train2022_4.zip -d /content/dataset/train/\n",
        "!unzip -qq train2022_5.zip -d /content/dataset/train/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Mq799sVYKD",
        "outputId": "5a33698a-4d1b-4eb4-dded-600dfd2ba2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/dataset/valid’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/dataset/valid\n",
        "!unzip -qq valid2022_1.zip -d /content/dataset/valid/\n",
        "!unzip -qq valid2022_2.zip -d /content/dataset/valid/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKqLeZxvKBfw"
      },
      "outputs": [],
      "source": [
        "!unzip -qq [training]dataset1.zip -d /content/dataset\n",
        "!unzip -qq [training]dataset2.zip -d /content/dataset\n",
        "!unzip -qq [training]dataset3.zip -d /content/dataset\n",
        "!unzip -qq [training]dataset4.zip -d /content/dataset\n",
        "!unzip -qq [training]dataset5.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPpkbpGIV3K_"
      },
      "outputs": [],
      "source": [
        "!mv /content/dataset/dataset1/* /content/dataset/train/\n",
        "!mv /content/dataset/dataset2/* /content/dataset/train/\n",
        "!mv /content/dataset/dataset3/* /content/dataset/train/\n",
        "!mv /content/dataset/dataset4/* /content/dataset/train/\n",
        "!mv /content/dataset/dataset5/* /content/dataset/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip -qq /content/[valid]dataset1.zip -d /content/valid\n",
        "!mv /content/valid/[valid]dataset1 /content/dataset/valid/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGPxXTvdKPzI",
        "outputId": "c9066e47-b521-4236-838d-07b0f57cf20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.ops import RoIAlign\n",
        "from torchvision import transforms\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmpxA0WZLeau"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "class ResizePad:\n",
        "    def __init__(self,size=(256,128),fill=0):\n",
        "        self.target_h, self.target_w = size\n",
        "        self.fill = fill\n",
        "    def __call__(self,img):\n",
        "        orig_w, orig_h = img.size\n",
        "        scale = min(self.target_w/orig_w, self.target_h/orig_h)\n",
        "        new_w, new_h = int(orig_w * scale),int(orig_h*scale)\n",
        "\n",
        "        img = img.resize((new_w,new_h), Image.BILINEAR)\n",
        "\n",
        "        new_img = Image.new(\"RGB\",(self.target_w,self.target_h),(self.fill,)*3)\n",
        "        paste_x = (self.target_w-new_w)//2\n",
        "        paste_y = (self.target_h-new_h)//2\n",
        "        new_img.paste(img,(paste_x,paste_y))\n",
        "\n",
        "        return new_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQKfzNRVHnt6"
      },
      "outputs": [],
      "source": [
        "class FolderGroupedBatchDataset:\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((256, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "        self.pid_to_paths = defaultdict(list)\n",
        "        for pid in os.listdir(root_dir):\n",
        "            pid_folder = os.path.join(root_dir, pid)\n",
        "            if os.path.isdir(pid_folder):\n",
        "                for fname in os.listdir(pid_folder):\n",
        "                    if fname.endswith('.png'):\n",
        "                        self.pid_to_paths[pid].append(os.path.join(pid_folder, fname))\n",
        "        self.pids = list(self.pid_to_paths.keys())\n",
        "\n",
        "\n",
        "    def sample(self, P, K):\n",
        "        selected_pids = random.sample(self.pids, min(P, len(self.pids)))\n",
        "        images, labels = [], []\n",
        "        for pid in selected_pids:\n",
        "            paths = self.pid_to_paths[pid]\n",
        "            chosen = random.choices(paths, k=K) if len(paths) < K else random.sample(paths, K)\n",
        "            for path in chosen:\n",
        "                img = Image.open(path).convert(\"RGB\")\n",
        "                img = self.transform(img)\n",
        "                images.append(img)\n",
        "                labels.append(pid)\n",
        "        return torch.stack(images), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY5ipiOi9ojv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "def get_custom_transform(apply_prob=0.3):\n",
        "    def random_obstacle_or_crop(img):\n",
        "        if random.random() > apply_prob:\n",
        "            return img  # No augmentation\n",
        "\n",
        "        mode = random.choice([\"obstacle\", \"bottom_crop\"])\n",
        "\n",
        "        if mode == \"obstacle\":\n",
        "            return add_obstacle(img)\n",
        "        elif mode == \"bottom_crop\":\n",
        "            return remove_bottom_half(img)\n",
        "        return img\n",
        "\n",
        "    def add_obstacle(img):\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "        x1 = random.randint(0, w // 2)\n",
        "        y1 = random.randint(0, h // 2)\n",
        "        x2 = x1 + random.randint(w // 8, w // 4)\n",
        "        y2 = y1 + random.randint(h // 8, h // 4)\n",
        "        draw.rectangle([x1, y1, x2, y2], fill=(0, 0, 0))\n",
        "        return img\n",
        "\n",
        "    def remove_bottom_half(img):\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        w, h = img.size\n",
        "        draw.rectangle([0, h//2, w, h], fill=(0, 0, 0))\n",
        "        return img\n",
        "\n",
        "    # Final composed transform\n",
        "    return transforms.Compose([\n",
        "        transforms.Lambda(random_obstacle_or_crop),\n",
        "        transforms.Resize((256, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzeoWpuyHn1V"
      },
      "outputs": [],
      "source": [
        "class FolderGroupedBatchTrainingDataset:\n",
        "    \"\"\"\n",
        "    Groups images by folder (person ID) for training only. Does not inherit from PyTorch Dataset\n",
        "    because it's not accessed by index but by a custom sampling method.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            ResizePad((256, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "        ])\n",
        "\n",
        "        self.pid_to_imgs = defaultdict(list)\n",
        "\n",
        "        for pid in os.listdir(root_dir):\n",
        "            folder = os.path.join(root_dir, pid)\n",
        "            if not os.path.isdir(folder): continue\n",
        "\n",
        "            for img_path in glob.glob(os.path.join(folder, '*.png')):\n",
        "                self.pid_to_imgs[pid].append(img_path)\n",
        "\n",
        "\n",
        "        self.pids = [pid for pid, imgs in self.pid_to_imgs.items() if len(imgs) >= 2]\n",
        "\n",
        "    def sample(self, P, K):\n",
        "        \"\"\"\n",
        "        Sample a batch of P identities with K images each.\n",
        "        Returns: images (tensor list), labels (list of pids)\n",
        "        \"\"\"\n",
        "        assert len(self.pids) >= P, \"Not enough unique IDs to sample.\"\n",
        "\n",
        "        batch_pids = random.sample(self.pids, P)\n",
        "        images = []\n",
        "        labels = []\n",
        "        for pid in batch_pids:\n",
        "            img_paths = random.sample(self.pid_to_imgs[pid], min(K, len(self.pid_to_imgs[pid])))\n",
        "            for path in img_paths:\n",
        "                img = Image.open(path).convert('RGB')\n",
        "                img = self.transform(img)\n",
        "                images.append(img)\n",
        "                labels.append(pid)\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxTT43meHn5o"
      },
      "outputs": [],
      "source": [
        "# Not used anymore.\n",
        "def batch_hard_triplet_loss(embeddings, labels, margin=1.0,device=torch.device('cpu')):\n",
        "    embeddings = F.normalize(embeddings, dim=1)\n",
        "    labels = torch.tensor([hash(x) for x in labels])  # hash to int\n",
        "    pdist = 1 - torch.matmul(embeddings, embeddings.T)\n",
        "    mask_pos = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
        "    mask_neg = ~mask_pos\n",
        "    mask_pos = mask_pos.float().to(device)\n",
        "    mask_neg = mask_neg.float().to(device)\n",
        "\n",
        "    hardest_pos = (pdist * mask_pos.float().to(device)).max(dim=1)[0]\n",
        "    hardest_neg = (pdist + mask_pos.float().to(device) * 10).min(dim=1)[0]\n",
        "    loss = F.relu(hardest_pos - hardest_neg + margin)\n",
        "    return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDhIVVo6Hn8I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pairwise_distances(embeddings):\n",
        "    # Compute cosine distance matrix\n",
        "    normed = F.normalize(embeddings, p=2, dim=1)\n",
        "    sim_matrix = torch.matmul(normed, normed.T)\n",
        "    dist_matrix = 1 - sim_matrix  # cosine distance\n",
        "    return dist_matrix\n",
        "\n",
        "def combined_triplet_loss(embeddings, labels, margin=1.0, alpha=0.5, device=torch.device('cpu')):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        embeddings: Tensor [N, D]\n",
        "        labels: List[str] or Tensor of IDs (can be string)\n",
        "        margin: Triplet margin\n",
        "        alpha: Weight for hard vs mean loss. alpha=0.5 → 50% hard, 50% mean\n",
        "    \"\"\"\n",
        "    # Convert string labels to integer indices\n",
        "    if isinstance(labels, list) and isinstance(labels[0], str):\n",
        "        label_to_index = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
        "        labels = [label_to_index[label] for label in labels]\n",
        "        labels = torch.tensor(labels, device=embeddings.device)\n",
        "    elif isinstance(labels, list):\n",
        "        labels = torch.tensor(labels, device=embeddings.device)\n",
        "    else:\n",
        "        labels = labels.to(embeddings.device)\n",
        "\n",
        "    pairwise_dist = pairwise_distances(embeddings)\n",
        "    N = embeddings.size(0)\n",
        "\n",
        "    loss_hard = 0.0\n",
        "    loss_mean = 0.0\n",
        "    valid_triplets = 0\n",
        "\n",
        "    for i in range(N):\n",
        "        anchor_label = labels[i]\n",
        "        dists = pairwise_dist[i]\n",
        "\n",
        "        is_pos = (labels == anchor_label) & (torch.arange(N, device=embeddings.device) != i)\n",
        "        is_neg = labels != anchor_label\n",
        "\n",
        "        if torch.sum(is_pos) == 0 or torch.sum(is_neg) == 0:\n",
        "            continue  # skip if no valid pairs\n",
        "\n",
        "        # Hardest positive and negative\n",
        "        hardest_pos = dists[is_pos].max()\n",
        "        hardest_neg = dists[is_neg].min()\n",
        "        hard_loss = F.relu(hardest_pos - hardest_neg + margin)\n",
        "\n",
        "        # Mean-based variant\n",
        "        mean_pos = dists[is_pos].mean()\n",
        "        mean_neg = dists[is_neg].mean()\n",
        "        mean_loss = F.relu(mean_pos - mean_neg + margin)\n",
        "\n",
        "        # Combine\n",
        "        loss = alpha * hard_loss + (1 - alpha) * mean_loss\n",
        "        loss_hard += loss\n",
        "        valid_triplets += 1\n",
        "\n",
        "    if valid_triplets == 0:\n",
        "        return torch.tensor(0.0, requires_grad=True, device=embeddings.device)\n",
        "\n",
        "    return loss_hard / valid_triplets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS73obD0Hn-p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VisionAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Multi-Head Self-Attention layer for vision tasks.\n",
        "    This layer is a core component of Vision Transformers (ViT).\n",
        "\n",
        "    Args:\n",
        "        dim (int): The embedding dimension of the input tokens.\n",
        "        heads (int): The number of attention heads.\n",
        "        dim_head (int, optional): The dimension of each attention head.\n",
        "                                  Defaults to dim // heads.\n",
        "        dropout (float, optional): Dropout rate. Defaults to 0.0.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, heads: int = 8, dim_head: int = 64, dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        # The scale factor is a crucial detail for stabilizing training.\n",
        "        # It's the inverse square root of the head dimension.\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x input shape: (batch_size, num_patches, dim)\n",
        "\n",
        "        # 1. Project input to Q, K, V\n",
        "        # Shape: (batch_size, num_patches, inner_dim * 3)\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "\n",
        "        # 2. Reshape Q, K, V for multi-head attention\n",
        "        # Change shape to: (batch_size, heads, num_patches, dim_head)\n",
        "        q, k, v = map(\n",
        "            lambda t: t.reshape(t.shape[0], t.shape[1], self.heads, -1).permute(0, 2, 1, 3),\n",
        "            qkv\n",
        "        )\n",
        "\n",
        "        # 3. Calculate scaled dot-product attention scores\n",
        "        # (q @ k.transpose) -> (b, h, n, d) @ (b, h, d, n) -> (b, h, n, n)\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        # 4. Apply softmax to get attention weights\n",
        "        attn_weights = self.softmax(dots)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # 5. Apply attention weights to V (values)\n",
        "        # (attn_weights @ v) -> (b, h, n, n) @ (b, h, n, d) -> (b, h, n, d)\n",
        "        attended_values = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # 6. Concatenate heads and project output\n",
        "        # First, reshape to (b, n, h*d) where h*d = inner_dim\n",
        "        out = attended_values.permute(0, 2, 1, 3).reshape(x.shape[0], x.shape[1], -1)\n",
        "\n",
        "        # Finally, project back to the original embedding dimension `dim`\n",
        "        return self.to_out(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qjzUKZuJulu"
      },
      "outputs": [],
      "source": [
        "class ReIDAtten_v2(nn.Module):\n",
        "    '''\n",
        "    ReID Atten v2\n",
        "    Reduced backbone of YOLOv11\n",
        "    Uses Attention Layer for head.\n",
        "    157,024 parameters.\n",
        "    '''\n",
        "    def __init__(self, yolo_weights='yolo11n.pt', emb_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        yolo_model = YOLO(yolo_weights)\n",
        "        self.backbone = nn.Sequential(*yolo_model.model.model[:5])\n",
        "\n",
        "\n",
        "        self.backbone_output_dim = self._get_feat_dim()\n",
        "        # Caveat : dim = dim_head = heads\n",
        "        self.attn = VisionAttentionLayer(\n",
        "            dim=self.backbone_output_dim,\n",
        "            heads=4,\n",
        "            dim_head=self.backbone_output_dim // 4)\n",
        "        self.embed = nn.Linear(self.backbone_output_dim, emb_dim)\n",
        "\n",
        "    def _get_feat_dim(self):\n",
        "        x = torch.zeros((1, 3, 256, 128))\n",
        "        with torch.no_grad():\n",
        "            x = self.backbone(x)\n",
        "            return x.shape[1]  # fix here\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)          # (B, C, H, W)\n",
        "\n",
        "\n",
        "        flat = x.flatten(2).transpose(1, 2)  # (B, H*W, C)\n",
        "        # print(\"input to atten:\", flat.shape)\n",
        "        att = self.attn(flat)              # (B, H*W, C)\n",
        "        # print(att.shape)\n",
        "        att = att.mean(dim=1)\n",
        "        # print(att.shape)            # (B, C)\n",
        "        embed = self.embed(att)             # (B, 128)\n",
        "        return nn.functional.normalize(embed, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXIrvbn353Jg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrWi7zmQHoA8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Validation\n",
        "@torch.no_grad()\n",
        "def validate_similarity(model, dataset, device, P=5, K=5, inter_K=16):\n",
        "    model.eval()\n",
        "    total_intra, total_inter, count_intra, count_inter = 0.0, 0.0, 0, 0\n",
        "\n",
        "    selected_pids = random.sample(dataset.pids, min(P, len(dataset.pids)))\n",
        "    for pid in selected_pids:\n",
        "        paths = dataset.pid_to_paths[pid]\n",
        "        if len(paths) < 2:\n",
        "            continue\n",
        "        chosen = random.sample(paths, min(K, len(paths)))\n",
        "        imgs = torch.stack([dataset.transform(Image.open(p).convert(\"RGB\")) for p in chosen]).to(device)\n",
        "        embs = F.normalize(model(imgs), dim=1)\n",
        "        for i in range(len(embs)):\n",
        "            for j in range(i + 1, len(embs)):\n",
        "                total_intra += F.cosine_similarity(embs[i].unsqueeze(0), embs[j].unsqueeze(0)).item()\n",
        "                count_intra += 1\n",
        "\n",
        "        # Inter\n",
        "        inter_paths = []\n",
        "        for _ in range(inter_K):\n",
        "            other_pid = random.choice([x for x in dataset.pids if x != pid])\n",
        "            other_img = random.choice(dataset.pid_to_paths[other_pid])\n",
        "            inter_paths.append(other_img)\n",
        "        inter_imgs = torch.stack([dataset.transform(Image.open(p).convert(\"RGB\")) for p in inter_paths]).to(device)\n",
        "        inter_embs = F.normalize(model(inter_imgs), dim=1)\n",
        "        for anchor in embs:\n",
        "            for inter in inter_embs:\n",
        "                total_inter += F.cosine_similarity(anchor.unsqueeze(0), inter.unsqueeze(0)).item()\n",
        "                count_inter += 1\n",
        "\n",
        "    avg_intra = total_intra / count_intra if count_intra else 0.0\n",
        "    avg_inter = total_inter / count_inter if count_inter else 0.0\n",
        "    return avg_intra, avg_inter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSjzvVIlJPPj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSKnUz91JPHs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# real_epoch=300\n",
        "# base_dir = os.getcwd()\n",
        "# model.load_state_dict(torch.load(os.path.join(base_dir, f\"saved_model2/ReIDPooling_{real_epoch}.pth\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcZ1XER9LQd2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csv-KOtWMC_f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HftOk1g9Mpb_"
      },
      "outputs": [],
      "source": [
        "# model.train()\n",
        "# imgs, labels = train_dataset.sample(P=16, K=4)\n",
        "# imgs = torch.stack(imgs).to(device)\n",
        "# imgs = imgs.to(device)\n",
        "# embeddings = model(imgs)\n",
        "# print(embeddings.shape)\n",
        "# print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR4JXNbNYzK"
      },
      "outputs": [],
      "source": [
        "# model = YOLOv11ReID().to(device)\n",
        "# pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "# print(pytorch_total_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T2xxYQSMwrb",
        "outputId": "daa9ae37-23c7-4394-95a6-0a39d01b6d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157024\n",
            "torch.Size([2, 128])\n"
          ]
        }
      ],
      "source": [
        "model = ReIDAtten_v2()\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(pytorch_total_params)\n",
        "\n",
        "dummy = torch.randn(2,3,256,128)\n",
        "out = model(dummy)  # shape: (2,128,16,8)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB7wRa3ALRoj",
        "outputId": "475ba951-74c4-4d14-e6a9-991d222bea50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.nn import TripletMarginLoss\n",
        "\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "model = ReIDAtten_v2().to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "real_epoch=0\n",
        "model.load_state_dict(torch.load(\"/content/ReIDAttenv2_29999.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "naFiaIPRJO-Y",
        "outputId": "c5714684-dc86-4f2c-e7a8-ff5d6245fd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3600] Loss: 0.7826\n",
            "train_intra : 0.6737804600596428, train_inter : -0.08082941194996238\n",
            "valid_intra : 0.7630690729618073, valid_inter : -0.011710610662121326\n",
            "[Epoch 3620] Loss: 0.7584\n",
            "train_intra : 0.7866354495286941, train_inter : 0.06454949941951782\n",
            "valid_intra : 0.7977882462739945, valid_inter : 0.007241774557624012\n",
            "[Epoch 3640] Loss: 0.8268\n",
            "train_intra : 0.664362509548664, train_inter : 0.008298321149777622\n",
            "valid_intra : 0.8068140208721161, valid_inter : -0.016444778421428056\n",
            "[Epoch 3660] Loss: 0.8282\n",
            "train_intra : 0.6660103227943182, train_inter : 0.05236610403517261\n",
            "valid_intra : 0.7575389701128006, valid_inter : 0.06248947187326848\n",
            "[Epoch 3680] Loss: 0.7320\n",
            "train_intra : 0.7734733176231384, train_inter : 0.020720789078623056\n",
            "valid_intra : 0.8112734293937683, valid_inter : 0.014781445246189833\n",
            "[Epoch 3700] Loss: 0.7265\n",
            "train_intra : 0.6904469680786133, train_inter : 0.0494121680711396\n",
            "valid_intra : 0.7649863308668137, valid_inter : 0.020217890026979147\n",
            "[Epoch 3720] Loss: 0.7801\n",
            "train_intra : 0.7700428372621536, train_inter : 0.04831553823547438\n",
            "valid_intra : 0.7866576516628265, valid_inter : 0.06780095155350864\n",
            "[Epoch 3740] Loss: 0.8701\n",
            "train_intra : 0.6772615544497966, train_inter : 0.0483741502976045\n",
            "valid_intra : 0.7329976314306259, valid_inter : 0.04616662967018783\n",
            "[Epoch 3760] Loss: 0.7822\n",
            "train_intra : 0.7420441967248916, train_inter : -0.04256596862338483\n",
            "valid_intra : 0.7572294217348099, valid_inter : -0.03820592948119156\n",
            "[Epoch 3780] Loss: 0.7680\n",
            "train_intra : 0.7635792481899262, train_inter : 0.07772236794233323\n",
            "valid_intra : 0.7660155940055847, valid_inter : 0.035454345098696646\n",
            "[Epoch 3800] Loss: 0.7915\n",
            "train_intra : 0.5849875746294856, train_inter : -0.05299375565722585\n",
            "valid_intra : 0.6809016917645931, valid_inter : 0.07080706197302788\n",
            "[Epoch 3820] Loss: 0.7815\n",
            "train_intra : 0.7087945657968521, train_inter : 0.06496180908521637\n",
            "valid_intra : 0.7746519374847413, valid_inter : 0.056373692974448206\n",
            "[Epoch 3840] Loss: 0.8279\n",
            "train_intra : 0.7468420474231243, train_inter : 0.032716907812282446\n",
            "valid_intra : 0.8286319345235824, valid_inter : -0.0046052528923610225\n",
            "[Epoch 3860] Loss: 0.8093\n",
            "train_intra : 0.7354061886668205, train_inter : -0.05686196207534522\n",
            "valid_intra : 0.6915277794003487, valid_inter : 0.049740781725849954\n",
            "[Epoch 3880] Loss: 0.7945\n",
            "train_intra : 0.7221245020627975, train_inter : 0.0657510022027418\n",
            "valid_intra : 0.7475987613201142, valid_inter : -0.0022208515787497164\n",
            "[Epoch 3900] Loss: 0.7881\n",
            "train_intra : 0.701425493657589, train_inter : 0.033704365589655935\n",
            "valid_intra : 0.7707993155717849, valid_inter : -0.00691850598435849\n",
            "[Epoch 3920] Loss: 0.7981\n",
            "train_intra : 0.7651012802124023, train_inter : 0.04522644530050456\n",
            "valid_intra : 0.7002645637094974, valid_inter : -0.008473403360694647\n",
            "[Epoch 3940] Loss: 0.7842\n",
            "train_intra : 0.6903502863645553, train_inter : 0.03729220666456968\n",
            "valid_intra : 0.7162153393030166, valid_inter : 0.07163384425453842\n",
            "[Epoch 3960] Loss: 0.8202\n",
            "train_intra : 0.7743815402686596, train_inter : 0.0491888306196779\n",
            "valid_intra : 0.7188094973564148, valid_inter : -0.03518386360025033\n",
            "[Epoch 3980] Loss: 0.8714\n",
            "train_intra : 0.71793526917696, train_inter : 0.08078828160185367\n",
            "valid_intra : 0.8085398596525192, valid_inter : 0.05146005931310356\n",
            "[Epoch 4000] Loss: 0.8453\n",
            "train_intra : 0.6973806196451187, train_inter : -0.0146270637284033\n",
            "valid_intra : 0.8456706237792969, valid_inter : -0.0192462624842301\n",
            "[Epoch 4020] Loss: 0.7463\n",
            "train_intra : 0.8614866840839386, train_inter : 0.008033314584754408\n",
            "valid_intra : 0.7816983893513679, valid_inter : 0.04561970267444849\n",
            "[Epoch 4040] Loss: 0.8159\n",
            "train_intra : 0.7887199115753174, train_inter : 0.07496075548697263\n",
            "valid_intra : 0.8127261161804199, valid_inter : -0.013351083253510296\n",
            "[Epoch 4060] Loss: 0.8948\n",
            "train_intra : 0.838045796751976, train_inter : 0.016804691522847862\n",
            "valid_intra : 0.7105648779496551, valid_inter : 0.14663923619315028\n",
            "[Epoch 4080] Loss: 0.7598\n",
            "train_intra : 0.5780749921500683, train_inter : -0.027986387982964517\n",
            "valid_intra : 0.7303305527567864, valid_inter : -0.06105850971536711\n",
            "[Epoch 4100] Loss: 0.7668\n",
            "train_intra : 0.6796746155619622, train_inter : 0.011317923495080323\n",
            "valid_intra : 0.6848011860251426, valid_inter : 0.03432204912416637\n",
            "[Epoch 4120] Loss: 0.7654\n",
            "train_intra : 0.6434731823205948, train_inter : -0.004785663387738168\n",
            "valid_intra : 0.735374459028244, valid_inter : 0.01824640723410994\n",
            "[Epoch 4140] Loss: 0.7189\n",
            "train_intra : 0.7005875903367996, train_inter : -0.0012081500887870789\n",
            "valid_intra : 0.80019109249115, valid_inter : 0.011500179562717676\n",
            "[Epoch 4160] Loss: 0.7849\n",
            "train_intra : 0.7665483230352401, train_inter : 0.01631964368512854\n",
            "valid_intra : 0.7974338841438293, valid_inter : -0.04020879459334537\n",
            "[Epoch 4180] Loss: 0.7596\n",
            "train_intra : 0.7790388798713684, train_inter : 0.08822915622033178\n",
            "valid_intra : 0.7741854584217072, valid_inter : 0.09142664549406618\n",
            "[Epoch 4200] Loss: 0.7667\n",
            "train_intra : 0.6795285809040069, train_inter : -0.028271067584864796\n",
            "valid_intra : 0.6865004388988019, valid_inter : 0.09659770912257955\n",
            "[Epoch 4220] Loss: 0.7896\n",
            "train_intra : 0.6917120963335037, train_inter : 0.06463867814280093\n",
            "valid_intra : 0.8412823565304279, valid_inter : 0.011614013361395337\n",
            "[Epoch 4240] Loss: 0.8602\n",
            "train_intra : 0.7101996678113938, train_inter : 0.030176100018434227\n",
            "valid_intra : 0.8837639462947845, valid_inter : 0.0178822680702433\n",
            "[Epoch 4260] Loss: 0.7425\n",
            "train_intra : 0.762102004289627, train_inter : 0.10523856534389779\n",
            "valid_intra : 0.7617998564243317, valid_inter : 0.037470298423431816\n",
            "[Epoch 4280] Loss: 0.8775\n",
            "train_intra : 0.7829136264324188, train_inter : -0.0014773941226303578\n",
            "valid_intra : 0.8178636699914932, valid_inter : 0.0786905124085024\n",
            "[Epoch 4300] Loss: 0.8310\n",
            "train_intra : 0.7800918161869049, train_inter : 0.10635359446518124\n",
            "valid_intra : 0.7815596944093705, valid_inter : 0.07907159243011846\n",
            "[Epoch 4320] Loss: 0.7802\n",
            "train_intra : 0.817277718782425, train_inter : 0.09295363589189946\n",
            "valid_intra : 0.778526303768158, valid_inter : 0.04619766567600891\n",
            "[Epoch 4340] Loss: 0.8183\n",
            "train_intra : 0.6872648322582244, train_inter : 0.06112624464556575\n",
            "valid_intra : 0.6971659007668495, valid_inter : 0.02593085128813982\n",
            "[Epoch 4360] Loss: 0.7310\n",
            "train_intra : 0.7533984434604645, train_inter : 0.04641630375757813\n",
            "valid_intra : 0.7513323146104812, valid_inter : 0.013615357504459098\n",
            "[Epoch 4380] Loss: 0.7333\n",
            "train_intra : 0.7394054985046387, train_inter : 0.06968277379870415\n",
            "valid_intra : 0.7826805049180985, valid_inter : 0.07494819620624185\n",
            "[Epoch 4400] Loss: 0.7012\n",
            "train_intra : 0.7202075207233429, train_inter : 0.03987634003162384\n",
            "valid_intra : 0.6950314757227898, valid_inter : -0.04633523610420525\n",
            "[Epoch 4420] Loss: 0.8375\n",
            "train_intra : 0.8101133000850678, train_inter : 0.029456813554279506\n",
            "valid_intra : 0.7278451079130173, valid_inter : -0.0018781205359846354\n",
            "[Epoch 4440] Loss: 0.7510\n",
            "train_intra : 0.7284399807453156, train_inter : 0.0503540741559118\n",
            "valid_intra : 0.7118538993597031, valid_inter : 0.04413847478106618\n",
            "[Epoch 4460] Loss: 0.8127\n",
            "train_intra : 0.8060632997751236, train_inter : 0.01137096491176635\n",
            "valid_intra : 0.8457309627532958, valid_inter : -0.03522545577958226\n",
            "[Epoch 4480] Loss: 0.8465\n",
            "train_intra : 0.7244700419902802, train_inter : 0.02011593404226005\n",
            "valid_intra : 0.8576693749427795, valid_inter : -0.1007607524562627\n",
            "[Epoch 4500] Loss: 0.7103\n",
            "train_intra : 0.7447651970386505, train_inter : 0.0709108470310457\n",
            "valid_intra : 0.8223330736160278, valid_inter : 0.05038916129153222\n",
            "[Epoch 4520] Loss: 0.8000\n",
            "train_intra : 0.7009047918021679, train_inter : 0.05998065904714167\n",
            "valid_intra : 0.8822923254966736, valid_inter : 0.01574441314442083\n",
            "[Epoch 4540] Loss: 0.7351\n",
            "train_intra : 0.6999628785252571, train_inter : 0.006525677295867354\n",
            "valid_intra : 0.7132536166906357, valid_inter : 0.01005395783809945\n",
            "[Epoch 4560] Loss: 0.7981\n",
            "train_intra : 0.7920743960142136, train_inter : 0.04839354027761147\n",
            "valid_intra : 0.714179866462946, valid_inter : 0.05621472924482077\n",
            "[Epoch 4580] Loss: 0.7589\n",
            "train_intra : 0.7753740787506104, train_inter : 0.08052252889610827\n",
            "valid_intra : 0.7950677168369293, valid_inter : -0.026512131764320657\n",
            "[Epoch 4600] Loss: 0.7673\n",
            "train_intra : 0.6778512816131115, train_inter : 0.11125870110932738\n",
            "valid_intra : 0.7915806460380554, valid_inter : 0.07514864678494632\n",
            "[Epoch 4620] Loss: 0.8911\n",
            "train_intra : 0.7799445647001266, train_inter : 0.02424145193072036\n",
            "valid_intra : 0.6865256696939468, valid_inter : -0.0010028271074406802\n",
            "[Epoch 4640] Loss: 0.8134\n",
            "train_intra : 0.8236954349279404, train_inter : -0.016341458579991013\n",
            "valid_intra : 0.5383620545268059, valid_inter : -0.0675567512633279\n",
            "[Epoch 4660] Loss: 0.8312\n",
            "train_intra : 0.6593555963039398, train_inter : -0.02805455311667174\n",
            "valid_intra : 0.7621841961145401, valid_inter : 0.05419548756210133\n",
            "[Epoch 4680] Loss: 0.8020\n",
            "train_intra : 0.7981853449344635, train_inter : 0.22790178892202675\n",
            "valid_intra : 0.808627781867981, valid_inter : 0.11295324132777751\n",
            "[Epoch 4700] Loss: 0.7821\n",
            "train_intra : 0.7599039596319198, train_inter : 0.1025697962846607\n",
            "valid_intra : 0.867391049861908, valid_inter : -0.014256461109034717\n",
            "[Epoch 4720] Loss: 0.9004\n",
            "train_intra : 0.7916407692432403, train_inter : 0.06373487088829279\n",
            "valid_intra : 0.7902017185091972, valid_inter : 0.025542664416134356\n",
            "[Epoch 4740] Loss: 0.7964\n",
            "train_intra : 0.7176451218128205, train_inter : -0.05378536915406585\n",
            "valid_intra : 0.725417058467865, valid_inter : 0.035625501645263284\n",
            "[Epoch 4760] Loss: 0.7510\n",
            "train_intra : 0.593033078983426, train_inter : -0.002042141833808273\n",
            "valid_intra : 0.8347061657905579, valid_inter : -0.011385208712890744\n",
            "[Epoch 4780] Loss: 0.7903\n",
            "train_intra : 0.7179603046178817, train_inter : -0.007885729887057095\n",
            "valid_intra : 0.7226190111041069, valid_inter : 0.029917730016168206\n",
            "[Epoch 4800] Loss: 0.7466\n",
            "train_intra : 0.741957682967186, train_inter : -0.018925921611953528\n",
            "valid_intra : 0.7830736303329467, valid_inter : 0.08322291171643884\n",
            "[Epoch 4820] Loss: 0.7935\n",
            "train_intra : 0.7178431034088135, train_inter : 0.08037223180290312\n",
            "valid_intra : 0.7567580485343933, valid_inter : -0.012569576939567924\n",
            "[Epoch 4840] Loss: 0.8655\n",
            "train_intra : 0.7331878983974457, train_inter : -0.003187321936711669\n",
            "valid_intra : 0.6490541708469391, valid_inter : -0.05697293621022254\n",
            "[Epoch 4860] Loss: 0.7902\n",
            "train_intra : 0.7862533557415009, train_inter : -0.031924956373404714\n",
            "valid_intra : 0.6780818142741919, valid_inter : 0.06029474469367415\n",
            "[Epoch 4880] Loss: 0.7516\n",
            "train_intra : 0.780065791606903, train_inter : 0.11408906921744347\n",
            "valid_intra : 0.8149569010734559, valid_inter : -0.007052635308355093\n",
            "[Epoch 4900] Loss: 0.7618\n",
            "train_intra : 0.6886445331573486, train_inter : 0.007961964430287481\n",
            "valid_intra : 0.774366803765297, valid_inter : 0.026874308413825928\n",
            "[Epoch 4920] Loss: 0.8244\n",
            "train_intra : 0.7508446151018142, train_inter : 0.04672010486712679\n",
            "valid_intra : 0.6741792052984238, valid_inter : -0.015933266053907574\n",
            "[Epoch 4940] Loss: 0.8462\n",
            "train_intra : 0.7298714572191238, train_inter : -0.018941861013881862\n",
            "valid_intra : 0.7945405399799347, valid_inter : 0.08388475781306624\n",
            "[Epoch 4960] Loss: 0.7727\n",
            "train_intra : 0.7332249835133553, train_inter : 0.0654767319187522\n",
            "valid_intra : 0.8370622718334197, valid_inter : 0.055615724849049\n",
            "[Epoch 4980] Loss: 0.8398\n",
            "train_intra : 0.6755883331596851, train_inter : -0.012967109205201268\n",
            "valid_intra : 0.7988326245546341, valid_inter : 0.05715071477694437\n",
            "[Epoch 5000] Loss: 0.8031\n",
            "train_intra : 0.7257886961102485, train_inter : -0.02594841522164643\n",
            "valid_intra : 0.7786355888843537, valid_inter : -0.019141952232457696\n",
            "[Epoch 5020] Loss: 0.8498\n",
            "train_intra : 0.7602354018390178, train_inter : 0.047581841603387146\n",
            "valid_intra : 0.7587787467241287, valid_inter : 0.010133104478009046\n",
            "[Epoch 5040] Loss: 0.8342\n",
            "train_intra : 0.733481308221817, train_inter : 0.03719563376856968\n",
            "valid_intra : 0.8134690999984742, valid_inter : -0.0376591518917121\n",
            "[Epoch 5060] Loss: 0.8628\n",
            "train_intra : 0.636837824806571, train_inter : -0.03839187549892813\n",
            "valid_intra : 0.7177094074338675, valid_inter : 0.0034718896355479954\n",
            "[Epoch 5080] Loss: 0.7146\n",
            "train_intra : 0.7884536814689637, train_inter : 0.049681165679357944\n",
            "valid_intra : 0.7342282366752625, valid_inter : 0.08317329502897337\n",
            "[Epoch 5100] Loss: 0.7874\n",
            "train_intra : 0.6651113058626652, train_inter : -0.01025210113148205\n",
            "valid_intra : 0.7427281296253204, valid_inter : 0.08990490929223598\n",
            "[Epoch 5120] Loss: 0.8598\n",
            "train_intra : 0.7229405844211578, train_inter : 0.16673498926102184\n",
            "valid_intra : 0.745048422664404, valid_inter : 0.04614805820165202\n",
            "[Epoch 5140] Loss: 0.7861\n",
            "train_intra : 0.7972027564048767, train_inter : -0.04583339526085183\n",
            "valid_intra : 0.7935646069049835, valid_inter : 0.035548183277715\n",
            "[Epoch 5160] Loss: 0.8660\n",
            "train_intra : 0.6100967271625996, train_inter : 0.1013285530207213\n",
            "valid_intra : 0.7415365086495876, valid_inter : 0.028835914523806423\n",
            "[Epoch 5180] Loss: 0.7844\n",
            "train_intra : 0.7805472512543201, train_inter : 0.060064774255733935\n",
            "valid_intra : 0.550598488599062, valid_inter : -0.016323211239650845\n",
            "[Epoch 5200] Loss: 0.8282\n",
            "train_intra : 0.760854484140873, train_inter : 0.12173530478961765\n",
            "valid_intra : 0.7816960352659226, valid_inter : 0.033751934375613926\n",
            "[Epoch 5220] Loss: 0.8039\n",
            "train_intra : 0.7234354209899903, train_inter : 0.03085772566962987\n",
            "valid_intra : 0.6583418717980385, valid_inter : 0.05893260278273374\n",
            "[Epoch 5240] Loss: 0.7689\n",
            "train_intra : 0.6745934587717056, train_inter : 0.1198136327881366\n",
            "valid_intra : 0.7945616793632507, valid_inter : 0.08957628791220486\n",
            "[Epoch 5260] Loss: 0.7031\n",
            "train_intra : 0.6818082716315985, train_inter : 0.060509328951593486\n",
            "valid_intra : 0.838505157828331, valid_inter : -0.005333766737021506\n",
            "[Epoch 5280] Loss: 0.7919\n",
            "train_intra : 0.8436777597665787, train_inter : -0.009646132942289115\n",
            "valid_intra : 0.7834889829158783, valid_inter : 0.003686503495555371\n",
            "[Epoch 5300] Loss: 0.7426\n",
            "train_intra : 0.803656969666481, train_inter : 0.021612081748899073\n",
            "valid_intra : 0.806478790640831, valid_inter : 0.010617557833902537\n",
            "[Epoch 5320] Loss: 0.8772\n",
            "train_intra : 0.7563315838575363, train_inter : 0.12906256587710233\n",
            "valid_intra : 0.7510229796171188, valid_inter : 0.1626681907242164\n",
            "[Epoch 5340] Loss: 0.7872\n",
            "train_intra : 0.7509417408704757, train_inter : 0.016679703323170543\n",
            "valid_intra : 0.7113954386115074, valid_inter : -0.055876335904467854\n",
            "[Epoch 5360] Loss: 0.7802\n",
            "train_intra : 0.7203697472810745, train_inter : -0.038381771389395\n",
            "valid_intra : 0.7988855339586735, valid_inter : -0.025546903964132072\n",
            "[Epoch 5380] Loss: 0.8522\n",
            "train_intra : 0.6759184511005878, train_inter : 0.05499764164211229\n",
            "valid_intra : 0.7672909277677536, valid_inter : 0.050757703320123256\n",
            "[Epoch 5400] Loss: 0.7343\n",
            "train_intra : 0.5618870221078396, train_inter : 0.028880501477979124\n",
            "valid_intra : 0.7285488539934158, valid_inter : -0.04776855891104788\n",
            "[Epoch 5420] Loss: 0.7297\n",
            "train_intra : 0.7098395776748657, train_inter : -0.03821676740422845\n",
            "valid_intra : 0.739089911878109, valid_inter : 0.04921428904403001\n",
            "[Epoch 5440] Loss: 0.7819\n",
            "train_intra : 0.8183192908763885, train_inter : 0.05069595532258973\n",
            "valid_intra : 0.8451628875732422, valid_inter : 0.030325598837807773\n",
            "[Epoch 5460] Loss: 0.7664\n",
            "train_intra : 0.7720722943544388, train_inter : 0.13737510393140837\n",
            "valid_intra : 0.7559169179201126, valid_inter : 0.056968994142953304\n",
            "[Epoch 5480] Loss: 0.8380\n",
            "train_intra : 0.7715223687887192, train_inter : 0.05844107940909453\n",
            "valid_intra : 0.7399133992195129, valid_inter : 0.0050820457516238095\n",
            "[Epoch 5500] Loss: 0.8169\n",
            "train_intra : 0.7345816439390183, train_inter : 0.015127608759794384\n",
            "valid_intra : 0.8690987730026245, valid_inter : 0.03854885609354824\n",
            "[Epoch 5520] Loss: 0.7375\n",
            "train_intra : 0.8073683786392212, train_inter : 0.040518922687042505\n",
            "valid_intra : 0.7276655262708664, valid_inter : 0.02419497676892206\n",
            "[Epoch 5540] Loss: 0.7280\n",
            "train_intra : 0.7122123637795448, train_inter : -0.027231918855104596\n",
            "valid_intra : 0.8927420485019684, valid_inter : 0.039318941340316084\n",
            "[Epoch 5560] Loss: 0.7183\n",
            "train_intra : 0.7860291385650635, train_inter : 0.06702156740706414\n",
            "valid_intra : 0.7992572867870331, valid_inter : 0.04819794912124053\n",
            "[Epoch 5580] Loss: 0.7471\n",
            "train_intra : 0.6900153984129429, train_inter : 0.051920149626675995\n",
            "valid_intra : 0.8631938660144806, valid_inter : 0.043487385322805494\n",
            "[Epoch 5600] Loss: 0.7929\n",
            "train_intra : 0.6832489365339279, train_inter : 0.07147558888187631\n",
            "valid_intra : 0.7279451882839203, valid_inter : 0.01595445234561339\n",
            "[Epoch 5620] Loss: 0.7375\n",
            "train_intra : 0.8186490213871003, train_inter : 0.041122635975480076\n",
            "valid_intra : 0.7905753332376481, valid_inter : 0.0902342460420914\n",
            "[Epoch 5640] Loss: 0.7845\n",
            "train_intra : 0.7001253497600556, train_inter : 0.04988857784308493\n",
            "valid_intra : 0.7884648223221302, valid_inter : -0.0699421693268232\n",
            "[Epoch 5660] Loss: 0.8009\n",
            "train_intra : 0.7136228570342064, train_inter : 0.07130964679876342\n",
            "valid_intra : 0.719687477350235, valid_inter : 0.0928001210372895\n",
            "[Epoch 5680] Loss: 0.8410\n",
            "train_intra : 0.7377478331327438, train_inter : 0.06699418432079256\n",
            "valid_intra : 0.8170938038825989, valid_inter : 0.11969411784783006\n",
            "[Epoch 5700] Loss: 0.7767\n",
            "train_intra : 0.7843699884414673, train_inter : 0.07800539619522169\n",
            "valid_intra : 0.6995054578781128, valid_inter : 0.07902044275775552\n",
            "[Epoch 5720] Loss: 0.8424\n",
            "train_intra : 0.773938150703907, train_inter : -0.08479571187403052\n",
            "valid_intra : 0.7096369338035583, valid_inter : 0.014804084217175842\n",
            "[Epoch 5740] Loss: 0.7955\n",
            "train_intra : 0.7692138430476189, train_inter : 0.03627030097413808\n",
            "valid_intra : 0.7349845477938652, valid_inter : 0.040898968474939464\n",
            "[Epoch 5760] Loss: 0.8454\n",
            "train_intra : 0.7915619122982025, train_inter : 0.1114240261982195\n",
            "valid_intra : 0.7812425369024276, valid_inter : 0.024824374415911735\n",
            "[Epoch 5780] Loss: 0.7373\n",
            "train_intra : 0.6776959293335676, train_inter : 0.014892784086987377\n",
            "valid_intra : 0.7955622243881225, valid_inter : 0.02057124544866383\n",
            "[Epoch 5800] Loss: 0.7780\n",
            "train_intra : 0.714562799334526, train_inter : 0.004541305173188448\n",
            "valid_intra : 0.8068885433673859, valid_inter : 0.0874340361636132\n",
            "[Epoch 5820] Loss: 0.8904\n",
            "train_intra : 0.6077322036027908, train_inter : 0.0070063506555743515\n",
            "valid_intra : 0.6735756516456604, valid_inter : -0.008670290673617274\n",
            "[Epoch 5840] Loss: 0.7778\n",
            "train_intra : 0.7040998400002718, train_inter : 0.03131275134161115\n",
            "valid_intra : 0.7446978080272675, valid_inter : 0.06471782193519175\n",
            "[Epoch 5860] Loss: 0.8352\n",
            "train_intra : 0.8136823517084122, train_inter : -0.005645513732451946\n",
            "valid_intra : 0.7914385676383973, valid_inter : 0.017512034513056277\n",
            "[Epoch 5880] Loss: 0.8474\n",
            "train_intra : 0.7575995576381683, train_inter : 0.004656013324856758\n",
            "valid_intra : 0.8318664979934692, valid_inter : -0.03056690883124247\n",
            "[Epoch 5900] Loss: 0.8120\n",
            "train_intra : 0.7715102154016494, train_inter : 0.018989382460713387\n",
            "valid_intra : 0.7764672790467739, valid_inter : 0.002738234461285174\n",
            "[Epoch 5920] Loss: 0.8143\n",
            "train_intra : 0.754736333489418, train_inter : -0.07771613370627165\n",
            "valid_intra : 0.7142925083637237, valid_inter : 0.1415390074951574\n",
            "[Epoch 5940] Loss: 0.7262\n",
            "train_intra : 0.7055607071518898, train_inter : 0.09030746466713026\n",
            "valid_intra : 0.6771827930212021, valid_inter : 0.04428389163920656\n",
            "[Epoch 5960] Loss: 0.8297\n",
            "train_intra : 0.6705923914909363, train_inter : 0.04945637764176354\n",
            "valid_intra : 0.748478279709816, valid_inter : 0.05269593258621171\n",
            "[Epoch 5980] Loss: 0.8011\n",
            "train_intra : 0.7963281434774399, train_inter : 0.05300024325959384\n",
            "valid_intra : 0.8146010613441468, valid_inter : 0.06692257770337165\n",
            "[Epoch 6000] Loss: 0.8349\n",
            "train_intra : 0.6311836466193199, train_inter : -0.04022635121596977\n",
            "valid_intra : 0.7755382204055786, valid_inter : -0.040978047809330745\n",
            "[Epoch 6020] Loss: 0.9011\n",
            "train_intra : 0.7692864036560059, train_inter : 0.0787630910309963\n",
            "valid_intra : 0.7636266827583313, valid_inter : 0.05588596339104697\n",
            "[Epoch 6040] Loss: 0.7385\n",
            "train_intra : 0.7745842283964157, train_inter : -0.06052862534066662\n",
            "valid_intra : 0.8096671414375305, valid_inter : 0.0859751858911477\n",
            "[Epoch 6060] Loss: 0.7698\n",
            "train_intra : 0.7343461239337921, train_inter : 0.029889708175323902\n",
            "valid_intra : 0.8323983752727508, valid_inter : 0.05071256228722632\n",
            "[Epoch 6080] Loss: 0.7249\n",
            "train_intra : 0.6990223014354706, train_inter : 0.0683025801833719\n",
            "valid_intra : 0.6957939118146896, valid_inter : 0.01198961665155366\n",
            "[Epoch 6100] Loss: 0.7740\n",
            "train_intra : 0.8203385525941849, train_inter : 0.06565474055241793\n",
            "valid_intra : 0.7082548958063125, valid_inter : -0.034637507216539236\n",
            "[Epoch 6120] Loss: 0.8468\n",
            "train_intra : 0.8112624096870422, train_inter : 0.04322590035386384\n",
            "valid_intra : 0.7510150353610515, valid_inter : 0.08456479510758072\n",
            "[Epoch 6140] Loss: 0.8073\n",
            "train_intra : 0.7494904530048371, train_inter : -0.1128822773322463\n",
            "valid_intra : 0.6865275633335114, valid_inter : 0.05240230896975845\n",
            "[Epoch 6160] Loss: 0.7432\n",
            "train_intra : 0.7295244252681732, train_inter : 0.07306034153793008\n",
            "valid_intra : 0.8284780251979827, valid_inter : 0.0136289948457852\n",
            "[Epoch 6180] Loss: 0.7458\n",
            "train_intra : 0.7719449599087238, train_inter : 0.0766210235026665\n",
            "valid_intra : 0.6977504473924637, valid_inter : -0.03912903611198999\n",
            "[Epoch 6200] Loss: 0.7043\n",
            "train_intra : 0.7060425186157226, train_inter : 0.026087394370697438\n",
            "valid_intra : 0.769503059387207, valid_inter : 0.04645000176271424\n",
            "[Epoch 6220] Loss: 0.8055\n",
            "train_intra : 0.7264141507074237, train_inter : 0.006284676468931138\n",
            "valid_intra : 0.8056040221452713, valid_inter : -0.08142065717140212\n",
            "[Epoch 6240] Loss: 0.7341\n",
            "train_intra : 0.8381842923164368, train_inter : -0.04861367569537833\n",
            "valid_intra : 0.8482299256324768, valid_inter : 0.01947720693424344\n",
            "[Epoch 6260] Loss: 0.7183\n",
            "train_intra : 0.6770245085656643, train_inter : -0.036329183138441294\n",
            "valid_intra : 0.752938694357872, valid_inter : -0.009847822189331055\n",
            "[Epoch 6280] Loss: 0.8428\n",
            "train_intra : 0.8638378202915191, train_inter : -0.030548015714157373\n",
            "valid_intra : 0.7655986136198044, valid_inter : 0.05025607404997572\n",
            "[Epoch 6300] Loss: 0.7857\n",
            "train_intra : 0.662834019958973, train_inter : 0.004628153145313263\n",
            "valid_intra : 0.6179297241568565, valid_inter : 0.019120514425449073\n",
            "[Epoch 6320] Loss: 0.7777\n",
            "train_intra : 0.7808404785394668, train_inter : -0.05068011886440218\n",
            "valid_intra : 0.8044363343715668, valid_inter : -0.04711717338999733\n",
            "[Epoch 6340] Loss: 0.8244\n",
            "train_intra : 0.7630837488174439, train_inter : 0.06876654098508879\n",
            "valid_intra : 0.7427652080357074, valid_inter : -0.03703396632801741\n",
            "[Epoch 6360] Loss: 0.8198\n",
            "train_intra : 0.7326300114393234, train_inter : -0.031079983215313405\n",
            "valid_intra : 0.6691209548711776, valid_inter : 0.03546388030983508\n",
            "[Epoch 6380] Loss: 0.7998\n",
            "train_intra : 0.756725606918335, train_inter : 0.005113869321066886\n",
            "valid_intra : 0.5951000103354454, valid_inter : -0.0066980747086927295\n",
            "[Epoch 6400] Loss: 0.7723\n",
            "train_intra : 0.7443543666601181, train_inter : 0.04757948838174343\n",
            "valid_intra : 0.7792159581184387, valid_inter : 0.0521211902028881\n",
            "[Epoch 6420] Loss: 0.8066\n",
            "train_intra : 0.779374760389328, train_inter : -0.010091553127858787\n",
            "valid_intra : 0.7177346479892731, valid_inter : 0.0657080986443907\n",
            "[Epoch 6440] Loss: 0.8490\n",
            "train_intra : 0.7123170608282089, train_inter : -0.006784690776839852\n",
            "valid_intra : 0.8282502943277359, valid_inter : -0.03519574609119445\n",
            "[Epoch 6460] Loss: 0.7049\n",
            "train_intra : 0.6786432808637619, train_inter : 0.05523569067474455\n",
            "valid_intra : 0.7414950996637344, valid_inter : 0.07980635540559888\n",
            "[Epoch 6480] Loss: 0.7130\n",
            "train_intra : 0.7318486177921295, train_inter : 0.04061529239523225\n",
            "valid_intra : 0.8066309630870819, valid_inter : -0.049361716136336324\n",
            "[Epoch 6500] Loss: 0.8073\n",
            "train_intra : 0.7409192085266113, train_inter : -0.042844170797616245\n",
            "valid_intra : 0.7274499478936195, valid_inter : -0.020971357161179184\n",
            "[Epoch 6520] Loss: 0.7395\n",
            "train_intra : 0.8133007329702377, train_inter : 0.049045108787249776\n",
            "valid_intra : 0.7583907285332679, valid_inter : -0.020170202706940473\n",
            "[Epoch 6540] Loss: 0.7025\n",
            "train_intra : 0.6583737164735795, train_inter : 0.07225274797994644\n",
            "valid_intra : 0.8440004318952561, valid_inter : -0.014152513244189322\n",
            "[Epoch 6560] Loss: 0.8725\n",
            "train_intra : 0.6353865799307823, train_inter : 0.05738695725332946\n",
            "valid_intra : 0.8278007662296295, valid_inter : 0.0731846514553763\n",
            "[Epoch 6580] Loss: 0.7794\n",
            "train_intra : 0.7154136747121811, train_inter : -0.04563731230562553\n",
            "valid_intra : 0.789072262942791, valid_inter : 0.03666009678505361\n",
            "[Epoch 6600] Loss: 0.7434\n",
            "train_intra : 0.7163501608371735, train_inter : 0.07114249050850048\n",
            "valid_intra : 0.724544484615326, valid_inter : 0.06158765270607546\n",
            "[Epoch 6620] Loss: 0.7673\n",
            "train_intra : 0.638993544280529, train_inter : 0.05520609655417502\n",
            "valid_intra : 0.7941941080987454, valid_inter : 0.08741966197500005\n",
            "[Epoch 6640] Loss: 0.8183\n",
            "train_intra : 0.7083612813800574, train_inter : 0.1017512658983469\n",
            "valid_intra : 0.7561149851977825, valid_inter : 0.05483142722863704\n",
            "[Epoch 6660] Loss: 0.7724\n",
            "train_intra : 0.7333021628856659, train_inter : 0.05102639213670045\n",
            "valid_intra : 0.6529065608978272, valid_inter : 0.04932519048452377\n",
            "[Epoch 6680] Loss: 0.8467\n",
            "train_intra : 0.7725727880001068, train_inter : 0.07486724806483835\n",
            "valid_intra : 0.7819090777635574, valid_inter : 0.12041826668661088\n",
            "[Epoch 6700] Loss: 0.8331\n",
            "train_intra : 0.8321719616651535, train_inter : -0.04542610759381205\n",
            "valid_intra : 0.797477759718895, valid_inter : 0.09568286221008748\n",
            "[Epoch 6720] Loss: 0.7875\n",
            "train_intra : 0.7432403916120529, train_inter : -0.0388475376740098\n",
            "valid_intra : 0.7261107796430588, valid_inter : 0.024773496775887905\n",
            "[Epoch 6740] Loss: 0.7688\n",
            "train_intra : 0.6963956892490387, train_inter : 0.06091420108801685\n",
            "valid_intra : 0.7325148606300353, valid_inter : 0.018846505247056486\n",
            "[Epoch 6760] Loss: 0.9022\n",
            "train_intra : 0.8145636785030365, train_inter : -0.11046282863244414\n",
            "valid_intra : 0.7626909881830215, valid_inter : 0.04074107176158577\n",
            "[Epoch 6780] Loss: 0.7514\n",
            "train_intra : 0.7569290861487389, train_inter : 0.019287709235213696\n",
            "valid_intra : 0.7596062105894089, valid_inter : -0.03419587950920686\n",
            "[Epoch 6800] Loss: 0.7963\n",
            "train_intra : 0.6934649163484573, train_inter : 0.009633619603700936\n",
            "valid_intra : 0.6929824379086494, valid_inter : 0.04551947290310636\n",
            "[Epoch 6820] Loss: 0.8031\n",
            "train_intra : 0.865324181318283, train_inter : -0.0020393554703332486\n",
            "valid_intra : 0.7326358838379383, valid_inter : 0.006282216683030128\n",
            "[Epoch 6840] Loss: 0.7566\n",
            "train_intra : 0.8170728123188019, train_inter : 0.09963037229143083\n",
            "valid_intra : 0.6622012790106236, valid_inter : 0.07400080516235903\n",
            "[Epoch 6860] Loss: 0.7305\n",
            "train_intra : 0.827568131685257, train_inter : 0.1102107548713684\n",
            "valid_intra : 0.7632189524173737, valid_inter : 0.049638858919497576\n",
            "[Epoch 6880] Loss: 0.7548\n",
            "train_intra : 0.7269866436719894, train_inter : 0.1198546379758045\n",
            "valid_intra : 0.7707392531633377, valid_inter : 0.07589166237972676\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-82-644304304.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-68-1536616373.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, P, K)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2319\u001b[0m                 )\n\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "torch.manual_seed(2356)\n",
        "\n",
        "# Augmentation added.\n",
        "train_dataset = FolderGroupedBatchTrainingDataset(\n",
        "    '/content/dataset/train',\n",
        "    transform=get_custom_transform(apply_prob=0.3))\n",
        "val_val_dataset = FolderGroupedBatchDataset('/content/dataset/train')\n",
        "tr_val_dataset = FolderGroupedBatchDataset('/content/dataset/valid')\n",
        "\n",
        "csv_log = f\"ReID_atten_train_logv1_{real_epoch}.csv\"\n",
        "with open(csv_log, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"loss\", \"train_intra\", \"train_inter\", \"val_intra\", \"val_inter\"])\n",
        "\n",
        "for epoch in range(50000):\n",
        "    model.train()\n",
        "    imgs, labels = train_dataset.sample(P=16, K=16)\n",
        "    imgs = torch.stack(imgs).to(device)\n",
        "    imgs = imgs.to(device)\n",
        "    embeddings = model(imgs)\n",
        "    loss = combined_triplet_loss(embeddings, labels,device=device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (real_epoch+1) % 20==0:\n",
        "        print(f\"[Epoch {real_epoch+1}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_intra, train_inter = validate_similarity(model, tr_val_dataset, device)\n",
        "        val_intra, val_inter = validate_similarity(model, val_val_dataset, device)\n",
        "        print(f\"train_intra : {train_intra}, train_inter : {train_inter}\")\n",
        "        print(f\"valid_intra : {val_intra}, valid_inter : {val_inter}\")\n",
        "\n",
        "        with open(csv_log, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([real_epoch+1, loss.item(), train_intra, train_inter, val_intra, val_inter])\n",
        "    if (real_epoch+1) % 500 == 0:\n",
        "        torch.save(model.state_dict(), 'ReID_attenv2/'+f\"ReIDAttenv2_{real_epoch+1}.pth\")\n",
        "\n",
        "    real_epoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "qQNS-xMR-07z",
        "outputId": "91f7727b-193e-402f-9560-9dc7243f0d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/ReID_attenv2/ (stored 0%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_6000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_3500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_1500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_4000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_6500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_2500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_4500.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_2000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_5000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_1000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_3000.pth (deflated 24%)\n",
            "  adding: content/ReID_attenv2/ReIDAttenv2_5500.pth (deflated 24%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_98eefca5-a99b-400e-951d-0728141f86e0\", \"pth_attenv2_aug.zip\", 6474329)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_664c8b79-c6e1-45ad-93c8-3e93b7ada000\", \"ReID_atten_train_logv1_0.csv\", 18587)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f8c09a76-2542-4ab4-a405-91903ef15359\", \"ReID_atten_train_logv1_3582.csv\", 17174)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!zip -r /content/pth_attenv2_aug.zip /content/ReID_attenv2\n",
        "from google.colab import files\n",
        "files.download(\"/content/pth_attenv2_aug.zip\")\n",
        "files.download(\"/content/ReID_atten_train_logv1_0.csv\")\n",
        "files.download(\"/content/ReID_atten_train_logv1_3582.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8m7LjcP-k0T"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_features_ids(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_features = []\n",
        "    all_ids = []\n",
        "\n",
        "    for images, ids in tqdm(dataloader, desc=\"Extracting features\"):\n",
        "        images = images.to(device)\n",
        "        emb = model(images)  # [B, 128]\n",
        "        emb = F.normalize(emb, dim=1)  # cosine normalization\n",
        "\n",
        "        all_features.append(emb.cpu())\n",
        "        all_ids.extend(ids)  # assume ids are strings or ints\n",
        "\n",
        "    features = torch.cat(all_features, dim=0)\n",
        "    return features, all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3ZJg-SjQ2RX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def compute_similarity_gaps(features, ids,show=False):\n",
        "    sim_matrix = cosine_similarity(features.numpy())  # [N, N]\n",
        "    N = len(ids)\n",
        "    gaps = []\n",
        "\n",
        "    for i in range(N):\n",
        "        query_id = ids[i]\n",
        "        sim_scores = sim_matrix[i]\n",
        "\n",
        "        # exclude self\n",
        "        sim_scores[i] = -np.inf\n",
        "\n",
        "        # positive scores (same ID, not self)\n",
        "        pos_mask = np.array([j != i and ids[j] == query_id for j in range(N)])\n",
        "        neg_mask = np.array([ids[j] != query_id for j in range(N)])\n",
        "\n",
        "        if not np.any(pos_mask) or not np.any(neg_mask):\n",
        "            continue  # skip if no pos/neg samples\n",
        "\n",
        "        best_pos = np.max(sim_scores[pos_mask])\n",
        "        best_neg = np.max(sim_scores[neg_mask])\n",
        "\n",
        "        gap = best_pos - best_neg\n",
        "        gaps.append(gap)\n",
        "\n",
        "    gaps = np.array(gaps)\n",
        "    print(f\"Avg similarity gap (pos - hardest neg): {np.mean(gaps):.4f}\")\n",
        "    print(f\"% queries where positive > negative: {(gaps > 0).mean()*100:.2f}%\")\n",
        "    if(show):\n",
        "        # Optional: visualize\n",
        "        plt.hist(gaps, bins=40, color='blue', edgecolor='black')\n",
        "        plt.title(\"Distribution of (best positive - hardest negative) similarity gaps\")\n",
        "        plt.xlabel(\"Similarity Gap\")\n",
        "        plt.ylabel(\"Number of queries\")\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "wAO0sc_hQ3Hx",
        "outputId": "9c38885a-a386-430b-eeb2-70b2fd568c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg similarity gap (pos - hardest neg): 0.1173\n",
            "% queries where positive > negative: 94.56%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "features, ids = extract_features_ids(model, val_loader, device)\n",
        "compute_similarity_gaps(features, ids, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i312_xG-WvXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu9GUia9W1bx"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SxvkvKNW61C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwWGm9FfY4Rj",
        "outputId": "c02f0355-299f-411b-f90a-9cc68933eafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg similarity (same ID):     0.2792\n",
            "Avg similarity (different ID): 0.0508\n"
          ]
        }
      ],
      "source": [
        "intra, inter = compute_intra_inter_similarity(features, ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5kXDELva_Tj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
