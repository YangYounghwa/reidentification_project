{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.ops import RoIAlign\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dd9aa",
   "metadata": {},
   "source": [
    "ipykernel               6.29.5\n",
    "ipython                 9.1.0\n",
    "matplotlib              3.10.1\n",
    "matplotlib-inline       0.1.6\n",
    "numpy                   2.2.6\n",
    "opencv-contrib-python   4.12.0.88\n",
    "opencv-python           4.10.0\n",
    "opencv-python-headless  4.10.0\n",
    "pandas                  2.3.1\n",
    "pillow                  11.3.0\n",
    "scikit-learn            1.6.1\n",
    "torch                   2.5.1\n",
    "torchinfo               1.8.0\n",
    "torchvision             0.20.1\n",
    "typing_extensions       4.12.2\n",
    "ultralytics             8.3.168\n",
    "ultralytics-thop        2.0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b61d8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "#model2 = torch.hub.load(\"ultralytics/yolov11\",\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90361bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2e1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ResizePad:\n",
    "    def __init__(self,size=(256,128),fill=0):\n",
    "        self.target_h, self.target_w = size\n",
    "        self.fill = fill\n",
    "    def __call__(self,img):\n",
    "        orig_w, orig_h = img.size\n",
    "        scale = min(self.target_w/orig_w, self.target_h/orig_h)\n",
    "        new_w, new_h = int(orig_w * scale),int(orig_h*scale)\n",
    "\n",
    "        img = img.resize((new_w,new_h), Image.BILINEAR)\n",
    "\n",
    "        new_img = Image.new(\"RGB\",(self.target_w,self.target_h),(self.fill,)*3)\n",
    "        paste_x = (self.target_w-new_w)//2\n",
    "        paste_y = (self.target_h-new_h)//2\n",
    "        new_img.paste(img,(paste_x,paste_y))\n",
    "\n",
    "        return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ceb5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset Class\n",
    "from PIL import Image\n",
    "\n",
    "class FolderBasedTripletDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            ResizePad((256, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "        self.id_index = {}  # pid -> list of image paths\n",
    "\n",
    "        for pid in os.listdir(root_dir):\n",
    "            folder = os.path.join(root_dir, pid)\n",
    "            if not os.path.isdir(folder): continue\n",
    "\n",
    "            images = [f for f in glob.glob(os.path.join(folder, '*.png')) if os.path.exists(f.replace('.png', '.xml'))]\n",
    "            if len(images) >= 2:\n",
    "                self.id_index[pid] = images\n",
    "\n",
    "        self.pids = list(self.id_index.keys())\n",
    "        assert len(self.pids) > 1, \"Need at least 2 different IDs for triplet loss.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_pid = self.pids[index]\n",
    "        anchor_img, positive_img = random.sample(self.id_index[anchor_pid], 2)\n",
    "        negative_pid = random.choice([pid for pid in self.pids if pid != anchor_pid])\n",
    "        negative_img = random.choice(self.id_index[negative_pid])\n",
    "\n",
    "        return self.load(anchor_img), self.load(positive_img), self.load(negative_img)\n",
    "\n",
    "    def load(self, path):\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e2dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatFolderTripletDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            ResizePad((256, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "        self.id_index = {}  # { person_id: [image_path1, image_path2, ...] }\n",
    "\n",
    "        png_files = glob.glob(os.path.join(folder, '*.png'))\n",
    "\n",
    "        for img_path in png_files:\n",
    "            xml_path = img_path.replace('.png', '.xml')\n",
    "            if not os.path.exists(xml_path):\n",
    "                continue\n",
    "\n",
    "            person_id = self.get_id_from_xml(xml_path)\n",
    "            if person_id:\n",
    "                self.id_index.setdefault(person_id, []).append(img_path)\n",
    "\n",
    "        self.pids = list(self.id_index.keys())\n",
    "        assert len(self.pids) > 1, \"Need at least 2 different IDs for triplet loss.\"\n",
    "\n",
    "    def get_id_from_xml(self, xml_path):\n",
    "        try:\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            object_elem = root.find('OBJECT')\n",
    "            if object_elem is not None:\n",
    "                return object_elem.attrib.get('ID')  # person ID from attribute\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to parse {xml_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_pid = self.pids[index]\n",
    "        anchor_img, positive_img = random.sample(self.id_index[anchor_pid], 2)\n",
    "        negative_pid = random.choice([pid for pid in self.pids if pid != anchor_pid])\n",
    "        negative_img = random.choice(self.id_index[negative_pid])\n",
    "\n",
    "        return self.load(anchor_img), self.load(positive_img), self.load(negative_img)\n",
    "\n",
    "    def load(self, path):\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fa3ef",
   "metadata": {},
   "source": [
    "```\n",
    "class YOLOv11ReID(nn.Module):\n",
    "    def __init__(self, yolo_weights='yolo11n.pt',emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.yolo=YOLO(yolo_weights)\n",
    "        self.encoder = nn.Sequential(*list(self.yolo.model.model.children())[:-2])\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self._get_feat_dim(),emb_dim)\n",
    "        \n",
    "    def _get_feat_dim(self):\n",
    "        x = torch.zeros((1,3,256,128))\n",
    "        with torch.no_grad():\n",
    "            f=self.encoder(x)\n",
    "            return f.shape[1]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        f = self.encoder(x)\n",
    "        pooled = self.pool(f).flatten(1)\n",
    "        emb = self.fc(pooled)\n",
    "        return nn.functional.normalize(emb,dim=1)\n",
    "```         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cfeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv11ReID(nn.Module):\n",
    "    def __init__(self, yolo_weights='yolo11n.pt', emb_dim=128):\n",
    "        super().__init__()\n",
    "        yolo_model = YOLO(yolo_weights)\n",
    "\n",
    "\n",
    "        self.backbone = nn.Sequential(\n",
    "          yolo_model.model.model[0],\n",
    "          yolo_model.model.model[1],\n",
    "          yolo_model.model.model[2],\n",
    "          yolo_model.model.model[3],\n",
    "          yolo_model.model.model[4],\n",
    "          yolo_model.model.model[5],\n",
    "          yolo_model.model.model[6],\n",
    "          yolo_model.model.model[7],\n",
    "          )\n",
    "\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self._get_feat_dim(), emb_dim)\n",
    "\n",
    "    def _get_feat_dim(self):\n",
    "        x = torch.zeros((1, 3, 256, 128))\n",
    "        with torch.no_grad():\n",
    "            f = self.backbone(x)\n",
    "\n",
    "            \n",
    "            # f = self.pool(f).flatten(1)\n",
    "            return f.shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        f = self.pool(x).flatten(1)\n",
    "        pooled = self.pool(x).flatten(1)  # âœ… apply once\n",
    "        emb = self.fc(pooled)\n",
    "        return nn.functional.normalize(emb, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd9887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690633fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = FolderBasedTripletDataset('..\\data\\sample_poc')\n",
    "\n",
    "loader =DataLoader(dataset,batch_size=16,shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset = FolderBasedTripletDataset('/content/dataset/dataset1')\n",
    "\n",
    "# def triplet_collate(batch):\n",
    "#     anchors, positives, negatives = zip(*batch)\n",
    "#     return (\n",
    "#         torch.stack(anchors),\n",
    "#         torch.stack(positives),\n",
    "#         torch.stack(negatives)\n",
    "#     )\n",
    "\n",
    "# loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, collate_fn=triplet_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLOv11ReID().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "triplet_loss = TripletMarginLoss(margin = 0.3)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    total_loss=0\n",
    "\n",
    "    for a,p,n in loader:\n",
    "        # print(f\"A: {a.shape}, P: {p.shape}, N: {n.shape}\")\n",
    "        a,p,n = a.to(device), p.to(device), n.to(device)\n",
    "        emb_a,emb_p,emb_n = model(a),model(p),model(n)\n",
    "        loss = triplet_loss(emb_a,emb_p,emb_n)\n",
    "        optimizer.zero_grad(); loss.backward();optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Avg Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../saved_models/reid_model_full_v0.1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pic_tag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
